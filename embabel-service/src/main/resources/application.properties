server.port=8085

spring.application.name=embabel-java-demo
#spring.main.web-application-type=none
spring.main.banner-mode=console

embabel.models.default-llm=gpt5-chat
embabel.models.llms.cheapest=claude-3-7-sonnet-openai
embabel.models.llms.best=gpt5-mini


embabel.agent.shell.chat.model=gpt5-mini
embabel.agent.shell.chat.temperature=0.3
embabel.agent.shell.chat.max-tokens=5000


embabel.models.default-embedding-model=qwen3-embedding:latest

spring.ai.ollama.base-url=http://172.30.133.12:11434

embabel.agent.platform.tools.includes.risk.description=risk Tools
embabel.agent.platform.tools.includes.risk.provider=risk-mcp
embabel.agent.platform.tools.includes.risk.tools=select_customer_buyer_info

# MCP 服务基础 URL（同步接口调用）
spring.ai.mcp.client.sse.connections.risk-mcp.url=http://49.0.206.228:80/kunlun-nacos/oa-mcp
# MCP 服务 SSE 实时事件流端点
spring.ai.mcp.client.sse.connections.risk-mcp.sse-endpoint=http://49.0.206.228:80/kunlun-nacos/oa-mcp/sse

spring.ai.mcp.client.enabled=true
spring.ai.mcp.client.name=embabel
spring.ai.mcp.client.version=1.0.0
spring.ai.mcp.client.request-timeout=30s
spring.ai.mcp.client.type=SYNC

logging.level.org.springframework.ai.mcp=DEBUG

spring.main.allow-bean-definition-overriding=true

############################################
# （可选）本地回退模型设置
############################################
# 如果远程失败，可改成本地 Ollama 服务
# embabel.ai.provider=custom
# embabel.ai.api-key=
# embabel.models.default-llm=qwen2.5:7b-instruct




# Embabel 模型配置 - 使用 DeepSeek v3
#embabel.models.default-llm=qwen3:latest
#embabel.models.llms.cheapest=qwen3:latest
#embabel.models.llms.best=qwen3:latest

# Shell agent 配置
#embabel.agent.shell.chat.model=qwen3:latest
#embabel.agent.shell.chat.temperature=0.3


# Spring AI DeepSeek API key
#spring.ai.deepseek.api-key=sk-8b5078e1b7ce4203a26e64883527eff1


#
#embabel.models.default-llm=gpt-4.1-mini
#embabel.models.llms.cheapest=gpt-4.1-nano
#
#embabel.models.llms.best=gpt-5
#
#
#embabel.agent.shell.chat.confirm-goals=false
#embabel.agent.shell.chat.multi-goal=false
#embabel.agent.shell.chat.bind-conversation=false
#embabel.agent.shell.chat.model=gpt-4.1-mini
#embabel.agent.shell.chat.temperature=0.3
#
#embabel.agent-platform.ranking.llm=gpt-4.1-mini
#
#
#embabel.fact-checker.models=gpt-4.1-mini,gpt-5-nano,gpt-5-mini
#embabel.fact-checker.max-concurrency=8
#
## Use a good LLM for this
#embabel.fact-checker.deduplication-model=gpt-4.1
#embabel.fact-checker.reasoning-word-count=50
#embabel.fact-checker.trusted-sources=Wikipedia,Wikidata,Britannica,BBC,Reuters,NY Times,ABC Australia
#embabel.fact-checker.untrusted-sources=reddit,4chan,twitter
#
